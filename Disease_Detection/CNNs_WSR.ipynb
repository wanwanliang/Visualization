{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs_WSR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZUGrQix4MY5U4UNZ06xxS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanwanliang/Research_Projects/blob/main/Disease_Detection/CNNs_WSR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyl3CltvCfs2"
      },
      "source": [
        " # Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSdCgBoYMLLQ"
      },
      "source": [
        "## install and load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WG8EjJGMOsY"
      },
      "source": [
        "!pip install geopandas\r\n",
        "!pip install rasterio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9TQTCuTZUUp"
      },
      "source": [
        "import rasterio as rio\r\n",
        "import geopandas as gpd\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import sklearn\r\n",
        "import tensorflow as tf\r\n",
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import google.colab\r\n",
        "from google.colab import drive\r\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l22oxr9Ob9jr"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHN7tNPAcQ48"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/UMN_Research/Data/wsr/image_200_bb45\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwLA-kmZVjX9"
      },
      "source": [
        "from keras.layers import Input, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout, AveragePooling2D, Flatten, ZeroPadding2D, MaxPooling2D, Add\r\n",
        "from keras.activations import relu, softmax\r\n",
        "from keras.models import Model\r\n",
        "from keras import regularizers, initializers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD2REYQNbMD1"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxAHVhc3D-f-"
      },
      "source": [
        "# Design Resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPxsT_w6EJGd"
      },
      "source": [
        "### Define identity block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlAj9gLpb47d"
      },
      "source": [
        "def identity_block(X,f,filters, stage, block):\r\n",
        "\r\n",
        "  # defining name basis\r\n",
        "  conv_name_base = 'res' + str(stage) + block + \"_branch\"\r\n",
        "  bn_name_base = 'bn' + str(stage) + block + \"_branch\"\r\n",
        "\r\n",
        "  F1, F2, F3 = filters\r\n",
        "\r\n",
        "  X_shortcut = X\r\n",
        "\r\n",
        "  # first component of main path\r\n",
        "  X = Conv2D(filters=F1, kernel_size=(1,1), strides=(1,1), padding='valid', name = conv_name_base + '2a', kernel_initializer=initializers.glorot_uniform(seed=0))(X)\r\n",
        "  X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  # second component of main path\r\n",
        "  X = Conv2D(filters=F2, kernel_size=(f,f), strides=(1,1), padding='same', name=conv_name_base + '2b', kernel_initializer=initializers.glorot_uniform(seed=0))(X)\r\n",
        "  X = BatchNormalization(axis = 3, name=bn_name_base + '2b')(X)\r\n",
        "  X =  Activation('relu')(X)\r\n",
        "\r\n",
        "  # third component of main path\r\n",
        "  X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = initializers.glorot_uniform(seed=0))(X)\r\n",
        "  X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\r\n",
        "\r\n",
        "  # final step\r\n",
        "  X = Add()([X, X_shortcut])\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYDorHqQEOp8"
      },
      "source": [
        "### Define convolutional block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZATMgxPM5v7F"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\r\n",
        "\r\n",
        "  # defining name basis\r\n",
        "  conv_name_base = 'res' + str(stage) + block + \"_branch\"\r\n",
        "  bn_name_base = 'bn' + str(stage) + block + \"_branch\"\r\n",
        "\r\n",
        "  # Retrieve Filters\r\n",
        "  F1, F2, F3 = filters\r\n",
        "\r\n",
        "  X_shortcut = X\r\n",
        "\r\n",
        "  # First component of main path \r\n",
        "  X = Conv2D(F1, (1,1), strides = (s,s), name= conv_name_base + \"2a\", kernel_initializer= initializers.glorot_uniform(seed=0))(X)\r\n",
        "  X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  # Second component of main path \r\n",
        "  X = Conv2D(filters= F2, kernel_size=(f,f), strides=(1,1), padding='same', name=conv_name_base + '2b', kernel_initializer= initializers.glorot_uniform(seed=0))(X)\r\n",
        "  X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  # Third component of main path \r\n",
        "  X = Conv2D(filters = F3, kernel_size=(1,1), strides=(1,1), padding='valid', name=conv_name_base + '2c', kernel_initializer=initializers.glorot_uniform(seed=0))(X)\r\n",
        "  X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\r\n",
        "\r\n",
        "  ##### SHORTCUT PATH #### \r\n",
        "  X_shortcut =  Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = initializers.glorot_uniform(seed=0))(X_shortcut)\r\n",
        "  X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\r\n",
        "\r\n",
        "  # Final step: Add shortcut value to main path, and pass it through a RELU activation \r\n",
        "  X = Add()([X, X_shortcut])\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLviL6aoEUel"
      },
      "source": [
        "### ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q05vttJGLof1"
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 5), classes=2):\r\n",
        "\r\n",
        "  X_input = Input(input_shape)\r\n",
        "\r\n",
        "  X = ZeroPadding2D((3,3))(X_input)\r\n",
        "\r\n",
        "  # stage 1 \r\n",
        "  X = Conv2D(64, (3,3), strides=(2,2), name='conv1', kernel_initializer=initializers.glorot_uniform(seed=0))(X)\r\n",
        "  X = BatchNormalization(axis=3, name='bn_conv1')(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "  X = MaxPooling2D((3,3), strides=(2,2), padding='same')(X)\r\n",
        "  \r\n",
        "  # stage 2\r\n",
        "  X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\r\n",
        "  X = identity_block(X, 3, [64,64,256], stage=2, block='b')\r\n",
        "  X = identity_block(X, 3, [64,64,256], stage=2, block='c')\r\n",
        "\r\n",
        "  # stage 3\r\n",
        "  X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\r\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\r\n",
        "  X = identity_block(X, 3, [128,128,512], stage=3, block='c')\r\n",
        "  X = identity_block(X, 3, [128,128,512], stage=3, block='d')\r\n",
        "\r\n",
        "  # stage 4\r\n",
        "  X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block='a', s=2)\r\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\r\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\r\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\r\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\r\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\r\n",
        "\r\n",
        "  # stage 5\r\n",
        "  X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\r\n",
        "  X = identity_block(X, 3, [512,512, 2048], stage=5, block='b')\r\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\r\n",
        "\r\n",
        "  # averge pooling\r\n",
        "  X = AveragePooling2D(name='avg_pool', padding='same')(X)\r\n",
        "\r\n",
        "  # output layer\r\n",
        "  X = Flatten()(X)\r\n",
        "  X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer= initializers.glorot_uniform(seed=0))(X)\r\n",
        "\r\n",
        "  # create model\r\n",
        "  model = Model(inputs = X_input, outputs= X, name='ResNet50')\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m8GfuU1VfZm"
      },
      "source": [
        "### ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja22fMMOUxNV"
      },
      "source": [
        "def ResNet18(input_shape = (64, 64, 5), classes=2):\r\n",
        "\r\n",
        "  X_input = Input(input_shape)\r\n",
        "\r\n",
        "  X = ZeroPadding2D((3,3))(X_input)\r\n",
        "\r\n",
        "  # stage 1 \r\n",
        "  X = Conv2D(64, (3,3), strides=(2,2), name='conv1', kernel_initializer=initializers.glorot_uniform(seed=0))(X)\r\n",
        "  X = BatchNormalization(axis=3, name='bn_conv1')(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "  X = MaxPooling2D((3,3), strides=(1,1), padding='same')(X)\r\n",
        "  \r\n",
        "  # stage 2\r\n",
        "  X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\r\n",
        "  X = identity_block(X, 3, [64,64,256], stage=2, block='b')\r\n",
        "\r\n",
        "\r\n",
        "  # stage 3\r\n",
        "  X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\r\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\r\n",
        "\r\n",
        "\r\n",
        "  # stage 4\r\n",
        "  X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block='a', s=2)\r\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\r\n",
        "\r\n",
        "\r\n",
        "  # stage 5\r\n",
        "  X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\r\n",
        "  X = identity_block(X, 3, [512,512, 2048], stage=5, block='b')\r\n",
        "\r\n",
        "\r\n",
        "  # averge pooling\r\n",
        "  X = AveragePooling2D(name='avg_pool', padding='same')(X)\r\n",
        "\r\n",
        "  # output layer\r\n",
        "  X = Flatten()(X)\r\n",
        "  X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer= initializers.glorot_uniform(seed=0))(X)\r\n",
        "\r\n",
        "  # create model\r\n",
        "  model = Model(inputs = X_input, outputs= X, name='ResNet50')\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLiZcXpqEoLP"
      },
      "source": [
        "# Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwhEVYRtwX22"
      },
      "source": [
        "os.chdir('/content/drive/Shared drives/WSR_data/Drone200ft/Multispectral_LargerPlotSize')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAuj4axFP4DW"
      },
      "source": [
        "### list and order files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TU7jkQk7w82"
      },
      "source": [
        "import glob\r\n",
        "t = glob.glob(\"*.tif\")\r\n",
        "# t2 = sorted(t)\r\n",
        "# os.remove('plot621 (1).tif')\r\n",
        "print(len(t))\r\n",
        "t[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDYiFUcgCW3K"
      },
      "source": [
        "nbs = []\r\n",
        "[nbs.append(int((td.split('plot')[1]).split('.')[0])) for td in t]\r\n",
        "nbs[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lY8_rifFTOz"
      },
      "source": [
        "all = zip(nbs, t)\r\n",
        "sorted_all = sorted(all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx-ZDCxzHkmj"
      },
      "source": [
        "t_sorted = [x for y, x in sorted_all]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dX6l1XNPcd3"
      },
      "source": [
        "t_sorted[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_wz-8zmPxt6"
      },
      "source": [
        "### load all images in one numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3ul1tvPSb4e"
      },
      "source": [
        "def tif2ary(tif):\r\n",
        "\r\n",
        "  raA = rio.open(tif)\r\n",
        "  arys = raA.read()\r\n",
        "\r\n",
        "  arys= arys.astype('float32')\r\n",
        "  arys =np.moveaxis(arys, 0, -1)\r\n",
        "\r\n",
        "  \r\n",
        "  return(arys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoAk0qKjTFgT"
      },
      "source": [
        "dt = None\r\n",
        "\r\n",
        "for tif in t_sorted:\r\n",
        "\r\n",
        "  ary = tif2ary(tif)\r\n",
        "  ary = ary[1:33, 1:33:,]\r\n",
        "\r\n",
        "  # resize image array to 64*64\r\n",
        "  ary = np.repeat(ary, 2, axis=1)\r\n",
        "  ary = np.repeat(ary, 2, axis=0)\r\n",
        "\r\n",
        "  ary = ary.reshape((1, 64, 64,5))\r\n",
        "\r\n",
        "  if dt is None:\r\n",
        "    dt = ary\r\n",
        "  else:\r\n",
        "    dt = np.concatenate((dt, ary), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyCIN_OrVBfY"
      },
      "source": [
        "dt.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HISi6_FaRv1G"
      },
      "source": [
        "min_val = [np.min(dt[:,:,:,i]) for i in range(5)]\r\n",
        "print(min_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO8ZmvhXON4A"
      },
      "source": [
        "max_val = [np.max(dt[:,:,:,i]) for i in range(5)]\r\n",
        "print(max_val)\r\n",
        "dt = dt/max_val\r\n",
        "print([np.max(dt[:,:,:,i]) for i in range(5)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvcVCNHBVuT-"
      },
      "source": [
        "y = pd.read_csv(\"../labels.csv\")\r\n",
        "print(y.shape)\r\n",
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tDxObuWZc_A"
      },
      "source": [
        "y.binary_1.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUE0Uw6TZlti"
      },
      "source": [
        "y = y['binary_1']\r\n",
        "y = np.asarray(y).reshape((-1,1))\r\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cBzX4vrSy1c"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "encoder = LabelEncoder()\r\n",
        "encoder.fit(y)\r\n",
        "y = encoder.transform(y)\r\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYNyvWr_ZpNG"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dt, y, random_state=16, shuffle=True, test_size=0.1)\r\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, random_state=16, test_size=0.15)\r\n",
        "\r\n",
        "print(\"Train size is: {}\".format(x_train.shape[0]))\r\n",
        "print(\"Test size is: {}\".format(x_test.shape[0]))\r\n",
        "print(\"Validation size is: {}\".format(x_val.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEi63zxwTMqX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN4PiyYvOWIj"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHo6ahSfOdHJ"
      },
      "source": [
        "ts = x_train[0]\r\n",
        "print(np.min(ts))\r\n",
        "print(np.max(ts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdkxLraRVVf_"
      },
      "source": [
        "\r\n",
        "# DL Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TULDayWH6m7R"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOFPNNRlTB4X"
      },
      "source": [
        "model = ResNet50(input_shape=(64, 64, 5), classes=2)\r\n",
        "#model = ResNet18(input_shape=(64, 64, 5), classes=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl-SjJtZRIqR"
      },
      "source": [
        "model.compile(optimizer= tf.keras.optimizers.Adam(lr=0.005),loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cefLlmQin_G"
      },
      "source": [
        "my_callbacks = [\r\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),\r\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='./models/ResNet50/model.{epoch:02d}-{val_loss:.2f}.h5', save_best_only=False, monitor='val_loss'),\r\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\r\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=1, epsilon=1e-4, min_lr = 0.000001, mode='auto')\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19sRiZXKZ2lp"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=200, batch_size=24, validation_data=(x_val, y_val), callbacks=my_callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA8rJrdqLBxi"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYQTh6C9KIuY"
      },
      "source": [
        "print(\"Testing accuracy: {}\".format(model.evaluate(x_test, y_test)[1]))\r\n",
        "print(\"Training accuracy: {}\".format(model.evaluate(x_train, y_train)[1]))\r\n",
        "print(\"Validation accuracy: {}\".format(model.evaluate(x_val, y_val)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFt2X_mMRQXH"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGsJeqeLRVmC"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "keras.models.save_model(model,\"ResNet18.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GvM2yhzSpjp"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eDaSF-JSsx_"
      },
      "source": [
        "os.chdir('/content/drive/Shared drives/WSR_data/Drone200ft/Multispectral_LargerPlotSize/models/ResNet18')\r\n",
        "trained_model = '../ResNet18/ResNet18.h5'\r\n",
        "model_best = keras.models.load_model(trained_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybKdp1aTS9vY"
      },
      "source": [
        "print(\"Testing accuracy: {}\".format(model_best.evaluate(x_test, y_test)[1]))\r\n",
        "print(\"Training accuracy: {}\".format(model_best.evaluate(x_train, y_train)[1]))\r\n",
        "print(\"Validation accuracy: {}\".format(model_best.evaluate(x_val, y_val)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NohaMANrQlya"
      },
      "source": [
        "# ML Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkjmgmMFES_k"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier as bc\r\n",
        "from sklearn.tree import DecisionTreeClassifier as dtc\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.datasets import make_moons\r\n",
        "from sklearn.ensemble import RandomForestClassifier as rfc\r\n",
        "from sklearn.ensemble import VotingClassifier as vc\r\n",
        "from sklearn.linear_model import LogisticRegression as lrc\r\n",
        "from sklearn.svm import SVC as svc\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrO0XSFBQoSt"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Idx3eGCQrc5"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/UMN_Research/Data/wsr\")\r\n",
        "dt = pd.read_csv('data.csv')\r\n",
        "print(dt.shape)\r\n",
        "dt.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Aexz2aWC02D"
      },
      "source": [
        "## Data Clearning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5ncNWMTC7Jg"
      },
      "source": [
        "dt2=dt\r\n",
        "dt2 = dt2.drop(['plotID'],axis=1)\r\n",
        "dt2.shape\r\n",
        "\r\n",
        "dt2['class2']=0\r\n",
        "dt2['class2'].iloc[(dt2.block==2)|(dt2.block==3)|(dt2.block==6)]=1\r\n",
        "\r\n",
        "dt2['class2'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWVT1DmrDHvx"
      },
      "source": [
        "dt3 = dt2\r\n",
        "dt3 = dt3.drop(['score','resistance_class_4','binary_2','block'],axis=1)\r\n",
        "print(dt3.shape)\r\n",
        "dt3.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fChuCC14DITq"
      },
      "source": [
        "### Check and remove NaN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEpcGC6MDMXx"
      },
      "source": [
        "pd.isnull(dt3).any(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JxtV4edDQrG"
      },
      "source": [
        "pd.isnull(dt3).sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmdUnm7mHQbW"
      },
      "source": [
        "dt3.loc[pd.isnull(dt3).any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KScYUtSnHoxG"
      },
      "source": [
        "dt3 = dt3.replace('#NAME?', np.NaN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ppogcylH872"
      },
      "source": [
        "dt3.loc[pd.isnull(dt3).any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCnkP5GrVFkP"
      },
      "source": [
        "dt4 = dt3.fillna(method='ffill')\r\n",
        "\r\n",
        "print(pd.isnull(dt4).sum(axis=0))\r\n",
        "dt4 = dt4.astype('float')\r\n",
        "print(dt4.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5M5zxLvDnIV"
      },
      "source": [
        "## Generate training, validation, and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2h_uXAdDZhx"
      },
      "source": [
        "x, y = dt4.drop(['class2'], axis=1), dt4['class2']\r\n",
        "x = StandardScaler().fit_transform(x)\r\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSIfkh48DfSZ"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=16, shuffle=True, test_size=0.15)\r\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, random_state=16, test_size=0.2)\r\n",
        "\r\n",
        "print(\"Train size is: {}\".format(x_train.shape[0]))\r\n",
        "print(\"Test size is: {}\".format(x_test.shape[0]))\r\n",
        "print(\"Validation size is: {}\".format(x_val.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PrxKBmmUhv-"
      },
      "source": [
        "## RF and SVM Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSxCVoyEMTDb"
      },
      "source": [
        "rf_clf = rfc(n_estimators=500, random_state=6) \r\n",
        "svm_clf = svc(gamma='scale', random_state=6)\r\n",
        "\r\n",
        "rf_clf.fit(x_train, y_train)\r\n",
        "svm_clf.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Eh9Z0kfOFhK"
      },
      "source": [
        "y_pred_rf = rf_clf.predict(x_test)\r\n",
        "y_pred_svm = svm_clf.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRyqXgRBOIr3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "print(\"Test Accuracy by RF: {}\".format(accuracy_score(y_test, y_pred_rf)))\r\n",
        "print(\"Test Accuracy by SVM: {}\".format(accuracy_score(y_test, y_pred_svm)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zaWlfIwOLkz"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "print(\"Confusion matrix by RF:\")\r\n",
        "print(confusion_matrix(y_test, y_pred_rf))\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Confusion matrix by SVM:\")\r\n",
        "print(confusion_matrix(y_test, y_pred_svm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okRTv3t7OOgt"
      },
      "source": [
        "## MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWyQD5OQOtNV"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na051_UrOvNO"
      },
      "source": [
        "mlp_model = keras.models.Sequential()\r\n",
        "mlp_model.add(Dense(30, input_dim = 26, activation='relu'))\r\n",
        "mlp_model.add(Dense(30, activation='relu'))\r\n",
        "mlp_model.add(Dense(2, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEKs8ky-Pxar"
      },
      "source": [
        "mlp_model.compile(loss='sparse_categorical_crossentropy',\r\n",
        "                  optimizer = keras.optimizers.Adam(learning_rate=0.01),\r\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h59NH8x_VMxw"
      },
      "source": [
        "my_callbacks = [\r\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100),\r\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='./MLP/model.{epoch:02d}-{val_loss:.2f}.h5', save_best_only=True, monitor='val_accuracy'),\r\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=1, epsilon=1e-4, min_lr = 0.000001, mode='auto')\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoYH6FusQLPl"
      },
      "source": [
        "fit_history = mlp_model.fit(x_train, y_train, epochs=200,batch_size=16, verbose=1, validation_data=(x_val, y_val), callbacks=my_callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNIKgMy3QQ1E"
      },
      "source": [
        "pd.DataFrame(fit_history.history).plot(figsize=(10,6))\r\n",
        "plt.grid(True)\r\n",
        "plt.gca().set_ylim(0,1)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGH4-ofcQUDf"
      },
      "source": [
        "y_pred_mlp = mlp_model.predict_classes(x_test)\r\n",
        "print(\"Test Accuracy by MLP: {}\".format(accuracy_score(y_test, y_pred_mlp)))\r\n",
        "\r\n",
        "print(\"Confusion matrix by MLP:\")\r\n",
        "print(confusion_matrix(y_test, y_pred_mlp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHfz08W8VaVg"
      },
      "source": [
        "y_pred_mlp = mlp_model.predict_classes(x_test)\r\n",
        "print(\"Test Accuracy by Final MLP: {}\".format(accuracy_score(y_test, y_pred_mlp)))\r\n",
        "\r\n",
        "print(\"Confusion matrix by Final MLP:\")\r\n",
        "print(confusion_matrix(y_test, y_pred_mlp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2PKKhXaTzSl"
      },
      "source": [
        "### Load best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MID52wnsUefO"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/UMN_Research/Data/wsr\")\r\n",
        "trained_model = './MLP/model.27-0.53.h5'\r\n",
        "model_best = keras.models.load_model(trained_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiF33k7SUs8y"
      },
      "source": [
        "y_pred_mlp = model_best.predict_classes(x_test)\r\n",
        "print(\"Test Accuracy by Best MLP: {}\".format(accuracy_score(y_test, y_pred_mlp)))\r\n",
        "\r\n",
        "print(\"Confusion matrix by Best MLP:\")\r\n",
        "print(confusion_matrix(y_test, y_pred_mlp))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}